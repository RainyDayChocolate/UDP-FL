{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 406 ms\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pprint\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "MAIN_PATH = os.getcwd().split(\"notebooks\")[0]\n",
    "sys.path.insert(0, MAIN_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shf22003\\DifferentialPrivacy\\py3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Run a Federated Learning experiment\n",
    "from data_loader.cifar10 import Cifar10DatasetManager\n",
    "from server.base_server import BaseServer\n",
    "from client.base_client import BaseClient\n",
    "from experiments.base_experiment import BaseExperiment\n",
    "from gradients.noise import GaussianNoiseGenerator, NoNoiseGenerator,StaircaseNoiseGenerator\n",
    "from metrics.classification import multiclass_accuracy\n",
    "from models.cifar_model import ResNet,ResNet18,ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoCifar10Experiment(BaseExperiment):\n",
    "    def __init__(self, \n",
    "                 client_num: int = 2, \n",
    "                 lr: float = 0.01, \n",
    "                 noise_generator=None,\n",
    "                 max_norm: float = 200,\n",
    "                 sampling_rate: float = 0.05):\n",
    "        if noise_generator is None:\n",
    "            noise_generator = NoNoiseGenerator()\n",
    "        self.noise_generator = noise_generator\n",
    "        self.lr = lr\n",
    "        self.max_norm = max_norm\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.client_num = client_num\n",
    "        self._init_server_clients(client_num, self.lr)\n",
    "        self._init_data(client_num)\n",
    "\n",
    "    def _init_server_clients(self, client_num, lr):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")        \n",
    "        model = ResNet18\n",
    "        self.clients = [BaseClient(model(lr=lr, max_norm=self.max_norm), \n",
    "                                   client_id=idx, \n",
    "                                   noise_generator=self.noise_generator)\n",
    "                        for idx in range(client_num)]\n",
    "        self.server = BaseServer(model(lr=lr, max_norm=self.max_norm))\n",
    "\n",
    "    def _init_data(self, client_num):\n",
    "        data_manager = Cifar10DatasetManager(n_parties=client_num, \n",
    "                                             sampling_lot_rate=self.sampling_rate)\n",
    "        self.client_train_datas = data_manager.train_loaders\n",
    "        self.valid_datas = data_manager.validation_loader\n",
    "        self.test_data = data_manager.test_loader\n",
    "\n",
    "    def evaluate_model(self, data):\n",
    "        total_correct = 0\n",
    "        total_sample_num = 0\n",
    "        with torch.no_grad():\n",
    "            for _, (inputs, target) in enumerate(data):\n",
    "                predict_labels = self.server.predict(inputs)\n",
    "                correct, sample_num = multiclass_accuracy(y_pred=predict_labels, \n",
    "                                                          y_true=target)\n",
    "                total_correct += correct\n",
    "                total_sample_num += sample_num\n",
    "                \n",
    "        return total_correct / total_sample_num\n",
    "        \n",
    "    def get_validation_result(self):\n",
    "        return self.evaluate_model(self.valid_datas)\n",
    "    \n",
    "    def get_test_result(self):\n",
    "        return self.evaluate_model(self.test_data)\n",
    "    \n",
    "    def aggeragate(self):\n",
    "        self.server.aggeragate_model(self.clients)\n",
    "    \n",
    "    def run(self, epochs: int, client_epochs: int):\n",
    "        self._init_data(self.client_num)\n",
    "        for client in self.clients:\n",
    "            client.set_training_mode(for_gradient=False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for client, client_train_data in self.shuffled_data(to_shuffle=False):\n",
    "                client.train(client_train_data, client_epochs=client_epochs)\n",
    "\n",
    "            self.aggeragate()\n",
    "\n",
    "            self.distribute_model()\n",
    "            print(self.get_validation_result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.memory_allocated(0) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_x = set()\n",
    "for param in EXPERIMENT.clients[0].model.parameters():\n",
    "    set_x.add(param.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = DemoCifar10Experiment(client_num=1,\n",
    "                                lr = 0.01, \n",
    "                        \n",
    "                                max_norm=1,\n",
    "                                sampling_rate=0.05,\n",
    "                                noise_generator=NoNoiseGenerator())\n",
    "EXPERIMENT.run(300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "0.1261\n",
      "0.1394\n",
      "0.1692\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m EXPERIMENT \u001b[39m=\u001b[39m DemoCifar10Experiment(client_num\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m      2\u001b[0m                                 lr \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m, \n\u001b[0;32m      3\u001b[0m                                 max_norm\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                 sampling_rate\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                 noise_generator\u001b[39m=\u001b[39mGaussianNoiseGenerator(sensitivity\u001b[39m=\u001b[39m\u001b[39m0.0559\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m EXPERIMENT\u001b[39m.\u001b[39;49mrun(\u001b[39m100\u001b[39;49m, \u001b[39m3\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[6], line 63\u001b[0m, in \u001b[0;36mDemoCifar10Experiment.run\u001b[1;34m(self, epochs, client_epochs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     62\u001b[0m     \u001b[39mfor\u001b[39;00m client, client_train_data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshuffled_data(to_shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 63\u001b[0m         client\u001b[39m.\u001b[39;49mtrain(client_train_data, client_epochs\u001b[39m=\u001b[39;49mclient_epochs)\n\u001b[0;32m     65\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggeragate()\n\u001b[0;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_model()\n",
      "File \u001b[1;32mc:\\Users\\shf22003\\DifferentialPrivacy\\client\\base_client.py:75\u001b[0m, in \u001b[0;36mBaseClient.train_for_model\u001b[1;34m(self, dataset, client_epochs)\u001b[0m\n\u001b[0;32m     73\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     74\u001b[0m sample_dataloder \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dataset)\n\u001b[1;32m---> 75\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain_dpsgd(sample_dataloder, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnoise_generator)\n",
      "File \u001b[1;32mc:\\Users\\shf22003\\DifferentialPrivacy\\models\\base_model.py:42\u001b[0m, in \u001b[0;36mBaseModel.train_dpsgd\u001b[1;34m(self, data_loader, noise_generator)\u001b[0m\n\u001b[0;32m     40\u001b[0m clip_grad_norm_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_norm)\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_parameters():\n\u001b[1;32m---> 42\u001b[0m     param\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m noise_generator\u001b[39m.\u001b[39;49mget_noise(param\u001b[39m.\u001b[39;49mgrad)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\shf22003\\DifferentialPrivacy\\gradients\\noise.py:17\u001b[0m, in \u001b[0;36mNoiseGenerator.get_noise\u001b[1;34m(self, gradient)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_noise\u001b[39m(\u001b[39mself\u001b[39m, gradient: torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m---> 17\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmechanism(gradient)\n",
      "File \u001b[1;32mc:\\Users\\shf22003\\DifferentialPrivacy\\gradients\\noise.py:41\u001b[0m, in \u001b[0;36mGaussianNoiseGenerator.mechanism\u001b[1;34m(self, gradient)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmechanism\u001b[39m(\u001b[39mself\u001b[39m, gradient: torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mempty(gradient\u001b[39m.\u001b[39;49msize())\u001b[39m.\u001b[39;49mnormal_(\u001b[39m0\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msensitivity)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EXPERIMENT = DemoCifar10Experiment(client_num=1,\n",
    "                                lr = 0.01, \n",
    "                                max_norm=1,\n",
    "                                sampling_rate=0.05,\n",
    "                                noise_generator=GaussianNoiseGenerator(sensitivity=0.0559))\n",
    "EXPERIMENT.run(100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = DemoCifar10Experiment(client_num=1,\n",
    "                                lr = 0.01, \n",
    "                                max_norm=1,\n",
    "                                sampling_rate=0.05,\n",
    "                                noise_generator=GaussianNoiseGenerator(sensitivity=0.0559))\n",
    "EXPERIMENT.run(100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "0.247\n",
      "0.2993\n",
      "0.36\n",
      "0.3547\n",
      "0.3628\n",
      "0.3986\n",
      "0.4223\n",
      "0.426\n",
      "0.464\n",
      "0.4642\n",
      "0.524\n",
      "0.5299\n",
      "0.5559\n",
      "0.5518\n",
      "0.6016\n",
      "0.5843\n",
      "0.6256\n",
      "0.6203\n",
      "0.6171\n",
      "0.6436\n",
      "0.6606\n",
      "0.6432\n",
      "0.6698\n",
      "0.6795\n",
      "0.6724\n",
      "0.6546\n",
      "0.7111\n",
      "0.7201\n",
      "0.7033\n",
      "0.7136\n",
      "0.7117\n",
      "0.7432\n",
      "0.7438\n",
      "0.724\n",
      "0.7482\n",
      "0.7529\n",
      "0.7461\n",
      "0.7508\n",
      "0.7714\n",
      "0.7711\n",
      "0.7965\n",
      "0.7838\n",
      "0.7981\n",
      "0.7818\n",
      "0.7964\n",
      "0.7734\n",
      "0.7866\n",
      "0.7951\n",
      "0.7863\n",
      "0.8021\n",
      "0.7931\n",
      "0.7819\n",
      "0.8041\n",
      "0.8179\n",
      "0.8136\n",
      "0.7994\n",
      "0.8126\n",
      "0.8246\n",
      "0.8133\n",
      "0.8068\n",
      "0.8171\n",
      "0.8197\n",
      "0.8278\n",
      "0.8214\n",
      "0.8065\n",
      "0.8208\n",
      "0.8167\n",
      "0.8263\n",
      "0.8247\n",
      "0.8245\n",
      "0.8383\n",
      "0.8348\n",
      "0.839\n",
      "0.8444\n",
      "0.8406\n",
      "0.8418\n",
      "0.8383\n",
      "0.8353\n",
      "0.8275\n",
      "0.847\n",
      "0.844\n",
      "0.8375\n",
      "0.8514\n",
      "0.8395\n",
      "0.8318\n",
      "0.839\n",
      "0.8489\n",
      "0.8334\n",
      "0.8484\n",
      "0.8553\n",
      "0.84\n",
      "0.8377\n",
      "0.8411\n",
      "0.8523\n",
      "0.8514\n",
      "0.8485\n",
      "0.8475\n",
      "0.8404\n",
      "0.846\n",
      "0.8468\n",
      "0.8436\n",
      "0.856\n",
      "0.8509\n",
      "0.8566\n",
      "0.8548\n",
      "0.8578\n",
      "0.8555\n",
      "0.8589\n",
      "0.8575\n",
      "0.8619\n",
      "0.8548\n",
      "0.8682\n",
      "0.8591\n",
      "0.8606\n",
      "0.8528\n",
      "0.8637\n",
      "0.8673\n",
      "0.8577\n",
      "0.8655\n",
      "0.8601\n",
      "0.865\n",
      "0.8662\n",
      "0.8704\n",
      "0.8687\n",
      "0.8685\n",
      "0.8638\n",
      "0.863\n",
      "0.8672\n",
      "0.8686\n",
      "0.8681\n",
      "0.8683\n",
      "0.8665\n",
      "0.8656\n",
      "0.8681\n",
      "0.8559\n",
      "0.8649\n",
      "0.8745\n",
      "0.8627\n",
      "0.867\n",
      "0.8673\n",
      "0.8654\n",
      "0.8644\n",
      "0.8722\n",
      "0.867\n",
      "0.8657\n",
      "0.8528\n",
      "0.8681\n",
      "0.8696\n",
      "0.875\n",
      "0.8726\n",
      "0.8627\n",
      "0.8734\n",
      "0.8701\n",
      "0.8712\n",
      "0.8773\n",
      "0.8775\n",
      "0.8776\n",
      "0.879\n",
      "0.8817\n",
      "0.8794\n",
      "0.8713\n",
      "0.8779\n",
      "0.8768\n",
      "0.8844\n",
      "0.8691\n",
      "0.8736\n",
      "0.8797\n",
      "0.8829\n",
      "0.8728\n",
      "0.8777\n",
      "0.8695\n",
      "0.8808\n",
      "0.8757\n",
      "0.885\n",
      "0.8819\n",
      "0.8862\n",
      "0.8787\n",
      "0.8745\n",
      "0.8789\n",
      "0.8804\n",
      "0.8803\n",
      "0.8815\n",
      "0.8799\n",
      "0.8722\n",
      "0.8797\n",
      "0.8815\n",
      "0.8792\n",
      "0.8809\n",
      "0.8726\n",
      "0.873\n",
      "0.8835\n",
      "0.8805\n",
      "0.8794\n",
      "0.8802\n",
      "0.8864\n",
      "0.8762\n",
      "0.8809\n",
      "0.8801\n",
      "0.8797\n",
      "0.8806\n",
      "0.885\n",
      "0.8828\n",
      "0.8772\n",
      "0.8737\n",
      "0.8853\n",
      "0.8782\n",
      "0.8862\n",
      "0.8836\n",
      "0.8793\n",
      "0.878\n",
      "0.8879\n",
      "0.8887\n",
      "0.8886\n",
      "0.8777\n",
      "0.8805\n",
      "0.8905\n",
      "0.8879\n",
      "0.8889\n",
      "0.8892\n",
      "0.8895\n",
      "0.8824\n",
      "0.8754\n",
      "0.8909\n",
      "0.8878\n",
      "0.8857\n",
      "0.8825\n",
      "0.8894\n",
      "0.8957\n",
      "0.8832\n",
      "0.8861\n",
      "0.877\n",
      "0.888\n",
      "0.8848\n",
      "0.8803\n",
      "0.889\n",
      "0.8887\n",
      "0.8885\n",
      "0.8813\n",
      "0.884\n",
      "0.8798\n",
      "0.8851\n",
      "0.8865\n",
      "0.8805\n",
      "0.8819\n",
      "0.8831\n",
      "0.89\n",
      "0.8892\n",
      "0.8882\n",
      "0.884\n",
      "0.8901\n",
      "0.8871\n",
      "0.8877\n",
      "0.8785\n",
      "0.8924\n",
      "0.8886\n",
      "0.8933\n",
      "0.8832\n",
      "0.8936\n",
      "0.8814\n",
      "0.8911\n",
      "0.8895\n",
      "0.8921\n",
      "0.8976\n",
      "0.8895\n",
      "0.8892\n",
      "0.8895\n",
      "0.897\n",
      "0.894\n",
      "0.8947\n",
      "0.8957\n",
      "0.8909\n",
      "0.8881\n",
      "0.8875\n",
      "0.8934\n",
      "0.8872\n",
      "0.8849\n",
      "0.8922\n",
      "0.8922\n",
      "0.8937\n",
      "0.8833\n",
      "0.8885\n",
      "0.894\n",
      "0.8952\n",
      "0.8914\n",
      "0.8804\n",
      "0.8917\n",
      "0.894\n",
      "0.8968\n",
      "0.8948\n",
      "0.8897\n",
      "0.894\n",
      "0.892\n",
      "0.8865\n",
      "0.8796\n",
      "0.8791\n",
      "0.8924\n",
      "0.8895\n",
      "0.8866\n",
      "0.8864\n",
      "0.8881\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT = DemoCifar10Experiment(client_num=1,\n",
    "                                lr = 0.01, \n",
    "                                max_norm=1,\n",
    "                                sampling_rate=0.05,\n",
    "                                noise_generator=NoNoiseGenerator())\n",
    "EXPERIMENT.run(300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load dataset\n",
    "batch_size = 32\n",
    "# data_manager = Cifar10DatasetManager(n_parties=1, \n",
    "#                                              sampling_lot_rate=0.01)\n",
    "# trainloader = data_manager.train_loaders\n",
    "# testset = data_manager.validation_loader\n",
    "# testloader = data_manager.test_loader\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x25713295600>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x14cf0a4f640>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 200] loss: 2.486\n",
      "[1, 400] loss: 2.251\n",
      "[1, 600] loss: 2.195\n",
      "[1, 800] loss: 2.100\n",
      "[1, 1000] loss: 2.090\n",
      "[1, 1200] loss: 2.094\n",
      "[1, 1400] loss: 2.073\n",
      "[1, 1600] loss: 2.013\n",
      "[1, 1800] loss: 1.984\n",
      "[1, 2000] loss: 2.003\n",
      "[1, 2200] loss: 1.939\n",
      "[1, 2400] loss: 1.928\n",
      "[1, 2600] loss: 1.910\n",
      "[1, 2800] loss: 1.891\n",
      "[1, 3000] loss: 1.862\n",
      "[1, 3200] loss: 1.842\n",
      "[1, 3400] loss: 1.918\n",
      "[1, 3600] loss: 1.845\n",
      "[1, 3800] loss: 1.769\n",
      "[1, 4000] loss: 1.755\n",
      "[1, 4200] loss: 1.816\n",
      "[1, 4400] loss: 1.772\n",
      "[1, 4600] loss: 1.698\n",
      "[1, 4800] loss: 1.795\n",
      "[1, 5000] loss: 1.747\n",
      "[1, 5200] loss: 1.652\n",
      "[1, 5400] loss: 1.687\n",
      "[1, 5600] loss: 1.665\n",
      "[1, 5800] loss: 1.644\n",
      "[1, 6000] loss: 1.674\n",
      "[1, 6200] loss: 1.639\n",
      "[1, 6400] loss: 1.670\n",
      "[1, 6600] loss: 1.614\n",
      "[1, 6800] loss: 1.563\n",
      "[1, 7000] loss: 1.611\n",
      "[1, 7200] loss: 1.565\n",
      "[1, 7400] loss: 1.563\n",
      "[1, 7600] loss: 1.540\n",
      "[1, 7800] loss: 1.494\n",
      "[1, 8000] loss: 1.471\n",
      "[1, 8200] loss: 1.560\n",
      "[1, 8400] loss: 1.539\n",
      "[1, 8600] loss: 1.469\n",
      "[1, 8800] loss: 1.473\n",
      "[1, 9000] loss: 1.418\n",
      "[1, 9200] loss: 1.365\n",
      "[1, 9400] loss: 1.454\n",
      "[1, 9600] loss: 1.386\n",
      "[1, 9800] loss: 1.367\n",
      "[1, 10000] loss: 1.402\n",
      "[1, 10200] loss: 1.352\n",
      "[1, 10400] loss: 1.393\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), model\u001b[39m.\u001b[39mmax_norm)\n\u001b[0;32m     21\u001b[0m model\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 23\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m200\u001b[39m \u001b[39m==\u001b[39m \u001b[39m199\u001b[39m:  \u001b[39m# Print average loss every 200 mini-batches\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] loss: \u001b[39m\u001b[39m{\u001b[39;00mrunning_loss\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m200\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "learning_rate = 0.001\n",
    "# model = ResNet(lr=learning_rate)\n",
    "model = model.to(model.device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(model.device), labels.to(model.device)\n",
    "\n",
    "        model.optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = model.loss_fn(outputs, labels).mean()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), model.max_norm)\n",
    "        model.optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 200 == 199:  # Print average loss every 200 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"cifar10_resnet.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EXPERIMENT.server.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 41.02%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(model.device), labels.to(model.device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

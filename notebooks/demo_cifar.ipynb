{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 338 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pprint\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "MAIN_PATH = os.getcwd().split(\"notebooks\")[0]\n",
    "sys.path.insert(0, MAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shf22003\\DifferentialPrivacy\\py3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Run a Federated Learning experiment\n",
    "from data_loader.cifar10 import Cifar10DatasetManager\n",
    "from server.base_server import BaseServer\n",
    "from client.base_client import BaseClient\n",
    "from experiments.base_experiment import BaseExperiment\n",
    "from gradients.noise import GaussianNoiseGenerator, NoNoiseGenerator,StaircaseNoiseGenerator\n",
    "from metrics.classification import multiclass_accuracy\n",
    "from models.cifar_model import SimpleCifarCNN, EfficientCifarCNN,ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoCifar10Experiment(BaseExperiment):\n",
    "    def __init__(self, \n",
    "                 client_num: int = 2, \n",
    "                 lr: float = 0.01, \n",
    "                 noise_generator=None,\n",
    "                 max_norm: float = 200,\n",
    "                 sampling_rate: float = 0.05):\n",
    "        if noise_generator is None:\n",
    "            noise_generator = NoNoiseGenerator()\n",
    "        self.noise_generator = noise_generator\n",
    "        self.lr = lr\n",
    "        self.max_norm = max_norm\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.client_num = client_num\n",
    "        self._init_server_clients(client_num, self.lr)\n",
    "        self._init_data(client_num)\n",
    "\n",
    "    def _init_server_clients(self, client_num, lr):\n",
    "        model = ResNet\n",
    "        self.clients = [BaseClient(model(lr=lr, max_norm=self.max_norm), \n",
    "                                   client_id=idx, \n",
    "                                   noise_generator=self.noise_generator)\n",
    "                        for idx in range(client_num)]\n",
    "        self.server = BaseServer(model(lr=lr, max_norm=self.max_norm))\n",
    "\n",
    "    def _init_data(self, client_num):\n",
    "        data_manager = Cifar10DatasetManager(n_parties=client_num, \n",
    "                                             sampling_lot_rate=self.sampling_rate)\n",
    "        self.client_train_datas = data_manager.train_loaders\n",
    "        self.valid_datas = data_manager.validation_loader\n",
    "        self.test_data = data_manager.test_loader\n",
    "\n",
    "    def evaluate_model(self, data):\n",
    "        total_correct = 0\n",
    "        total_sample_num = 0\n",
    "        with torch.no_grad():\n",
    "            for _, (inputs, target) in enumerate(data):\n",
    "                predict_labels = self.server.predict(inputs)\n",
    "                correct, sample_num = multiclass_accuracy(y_pred=predict_labels, \n",
    "                                                          y_true=target)\n",
    "                total_correct += correct\n",
    "                total_sample_num += sample_num\n",
    "                \n",
    "        return total_correct / total_sample_num\n",
    "        \n",
    "    def get_validation_result(self):\n",
    "        return self.evaluate_model(self.valid_datas)\n",
    "    \n",
    "    def get_test_result(self):\n",
    "        return self.evaluate_model(self.test_data)\n",
    "    \n",
    "    def aggeragate(self):\n",
    "        self.server.aggeragate_model(self.clients)\n",
    "    \n",
    "    def run(self, epochs: int, client_epochs: int):\n",
    "        self._init_data(self.client_num)\n",
    "        for client in self.clients:\n",
    "            client.set_training_mode(for_gradient=False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for client, client_train_data in self.shuffled_data(to_shuffle=False):\n",
    "                client.train(client_train_data, client_epochs=client_epochs)\n",
    "\n",
    "            self.aggeragate()\n",
    "\n",
    "            self.distribute_model()\n",
    "            print(self.get_validation_result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT = DemoCifar10Experiment(client_num=1,\n",
    "                                lr = 0.001, \n",
    "                                max_norm=1000,\n",
    "                                sampling_rate=0.05,\n",
    "                                noise_generator=NoNoiseGenerator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "0.352\n",
      "0.4461\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT.run(2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT.aggeragate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param(model):\n",
    "    for param in model.parameters():\n",
    "        print(param.sum())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9127, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_param(EXPERIMENT.clients[0].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9127, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_param(EXPERIMENT.server.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load dataset\n",
    "batch_size = 32\n",
    "# data_manager = Cifar10DatasetManager(n_parties=1, \n",
    "#                                              sampling_lot_rate=0.01)\n",
    "# trainloader = data_manager.train_loaders\n",
    "# testset = data_manager.validation_loader\n",
    "# testloader = data_manager.test_loader\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x25713295600>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x14cf0a4f640>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 200] loss: 2.486\n",
      "[1, 400] loss: 2.251\n",
      "[1, 600] loss: 2.195\n",
      "[1, 800] loss: 2.100\n",
      "[1, 1000] loss: 2.090\n",
      "[1, 1200] loss: 2.094\n",
      "[1, 1400] loss: 2.073\n",
      "[1, 1600] loss: 2.013\n",
      "[1, 1800] loss: 1.984\n",
      "[1, 2000] loss: 2.003\n",
      "[1, 2200] loss: 1.939\n",
      "[1, 2400] loss: 1.928\n",
      "[1, 2600] loss: 1.910\n",
      "[1, 2800] loss: 1.891\n",
      "[1, 3000] loss: 1.862\n",
      "[1, 3200] loss: 1.842\n",
      "[1, 3400] loss: 1.918\n",
      "[1, 3600] loss: 1.845\n",
      "[1, 3800] loss: 1.769\n",
      "[1, 4000] loss: 1.755\n",
      "[1, 4200] loss: 1.816\n",
      "[1, 4400] loss: 1.772\n",
      "[1, 4600] loss: 1.698\n",
      "[1, 4800] loss: 1.795\n",
      "[1, 5000] loss: 1.747\n",
      "[1, 5200] loss: 1.652\n",
      "[1, 5400] loss: 1.687\n",
      "[1, 5600] loss: 1.665\n",
      "[1, 5800] loss: 1.644\n",
      "[1, 6000] loss: 1.674\n",
      "[1, 6200] loss: 1.639\n",
      "[1, 6400] loss: 1.670\n",
      "[1, 6600] loss: 1.614\n",
      "[1, 6800] loss: 1.563\n",
      "[1, 7000] loss: 1.611\n",
      "[1, 7200] loss: 1.565\n",
      "[1, 7400] loss: 1.563\n",
      "[1, 7600] loss: 1.540\n",
      "[1, 7800] loss: 1.494\n",
      "[1, 8000] loss: 1.471\n",
      "[1, 8200] loss: 1.560\n",
      "[1, 8400] loss: 1.539\n",
      "[1, 8600] loss: 1.469\n",
      "[1, 8800] loss: 1.473\n",
      "[1, 9000] loss: 1.418\n",
      "[1, 9200] loss: 1.365\n",
      "[1, 9400] loss: 1.454\n",
      "[1, 9600] loss: 1.386\n",
      "[1, 9800] loss: 1.367\n",
      "[1, 10000] loss: 1.402\n",
      "[1, 10200] loss: 1.352\n",
      "[1, 10400] loss: 1.393\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), model\u001b[39m.\u001b[39mmax_norm)\n\u001b[0;32m     21\u001b[0m model\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 23\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m200\u001b[39m \u001b[39m==\u001b[39m \u001b[39m199\u001b[39m:  \u001b[39m# Print average loss every 200 mini-batches\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] loss: \u001b[39m\u001b[39m{\u001b[39;00mrunning_loss\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m200\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "learning_rate = 0.001\n",
    "# model = ResNet(lr=learning_rate)\n",
    "model = model.to(model.device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(model.device), labels.to(model.device)\n",
    "\n",
    "        model.optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = model.loss_fn(outputs, labels).mean()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), model.max_norm)\n",
    "        model.optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 200 == 199:  # Print average loss every 200 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"cifar10_resnet.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EXPERIMENT.server.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 41.02%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(model.device), labels.to(model.device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
